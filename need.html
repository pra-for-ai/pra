<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- Basic SEO -->
    <meta name="description" content="Understanding why probabilistic risk assessment is crucial for AI systems: addressing emergent behaviors, systemic risks, and complex interactions that traditional risk assessment methods cannot capture.">
    <meta name="author" content="Center for AI Risk Management & Alignment">
    
    <!-- Keywords -->
    <meta name="keywords" content="AI risk assessment need, AI safety evaluation, systemic risk assessment, probabilistic risk assessment importance, prospective risk assessment need, AI risk methodology, AI risk evaluation, AI threat assessment, AI hazard analysis, risk pathway methodology, systemic risk evaluation, emergent behavior assessment, AI capability assessment, AI impact evaluation, complex system risk, AI safety methodology, systemic risk methodology, AI risk analysis">

    <!-- Open Graph Protocol Tags -->
    <meta property="og:title" content="PRA Framework: The Need for PRA in AI">
    <meta property="og:description" content="Why traditional risk assessment methods fall short for AI systems and how probabilistic risk assessment addresses unique challenges in AI safety and governance.">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="PRA for AI">

    <!-- Schema.org markup for Google -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "TechArticle",
      "headline": "The Need for Probabilistic Risk Assessment in AI",
      "description": "Exploring why probabilistic and prospective risk assessment methods are essential for evaluating AI systems and their potential societal impacts.",
      "keywords": "AI risk assessment, systemic risk methodology, emergent behavior analysis, AI safety evaluation, probabilistic assessment need",
      "author": {
        "@type": "Organization",
        "name": "Center for AI Risk Management & Alignment"
      },
      "inLanguage": "en",
      "about": {
        "@type": "Thing",
        "name": "Artificial Intelligence Risk Assessment"
      }
    }
    </script>

    <!-- Additional Meta Tags -->
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="format-detection" content="telephone=no">
    <meta name="theme-color" content="#ffffff">

    <!-- Light mode favicon -->
    <link rel="icon" href="Images/favicon.png" media="(prefers-color-scheme: light)">

    <!-- Dark mode favicon -->
    <link rel="icon" href="Images/favicondark.png" media="(prefers-color-scheme: dark)">

    <title>PRA Framework: The Need for PRA in AI</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="header-content">
            <div class="header-title">
                <h1><a href="index.html" style="color: #F5F5F5; text-decoration: none;">PRA Framework</a></h1>
                <div class="subtitle">The Need for PRA in AI</div>
            </div>
            <nav>
              <a href="index.html">OVERVIEW</a>
              <a href="need.html">NEED</a>
              <a href="taxonomy.html">TAXONOMY</a>
              <a href="workbook.html">WORKBOOK</a>
              <a href="paper.html">PAPER</a>
          </nav>
        </div>
    </header>
    <div class="header-bar">‎</div>
    <main>
        <div class="content">
            <h2 style="width: 100%; font-weight: normal; color: #333333; margin-top: 0cm;">Characteristics of Increasingly General-Purpose AI Risk</h2>

            <p>Advanced AI systems possess unprecedented leverage and unique characteristics that set them apart from traditional technologies:</p>

            <ol>
                <li><b>Global impact:</b> Given their widespread direct adoption, broad proliferation, and unprecedented leverage, AI systems have the potential for widespread, even global, effects.</li>
                
                <li><b>Emergent behaviors:</b> AI systems can develop behaviors and pursue objectives that emerge from, but were not explicitly encoded in, their training. These behaviors often lack historical precedent, making risk assessment through traditional pattern-matching difficult.</li>
                
                <li><b>Dual use threats:</b> Malicious actors may attempt to exploit or manipulate AI models, or simply give them purposely harmful goals.</li>
                
                <li><b>Vulnerability to systemic failures:</b> Many AI safety measures rely on centralized controls or specific constraints. If these are compromised—for instance, through unauthorized access to model weights or unrestricted internet access—the consequences could be severe and far-reaching.</li>
                
                <li><b>Rapid evolution:</b> The field of AI is advancing at an unprecedented pace, requiring risk assessment methods that can keep up with and anticipate new developments. AI agents can show unexpected capability jumps and may gain the ability to replicate and improve themselves at rapid speeds.</li>
                
                <li><b>Loss of control:</b> The speed at which unintended side effects develop, combined with the complexity of AI systems, often surpasses human capability to intervene effectively once a harmful chain of events is set in motion.</li>
                
                <li><b>Complex interactions:</b> AI systems can interact with their environment, other AI systems, and humans in adaptive, self-reinforcing ways, often producing emergent behaviors and cascading risks that are difficult to foresee or contain.</li>
            </ol>

            <p>As AI models advance in size and capability, they demonstrate an increasingly general breadth of competences, within which they enable superhuman speed and abilities. Empirical evidence sets a lower bound on the capabilities and dangers that AI models can pose: deepfake creation, specific vectors of cyber offense uplift (i.e., enhancement of cyber-attack strategies and effectiveness), and hallucination are examples of readily reproducible risks. Benchmarks and traditional evals are imperfect tools to measure these, but they get much of the way there.</p>
                        
            <p>But the risks posed by today's and tomorrow's models enter territory for which no precedent yet exists. Large problems lurk beyond the horizon of what can be tested in a few weeks. AI risk assessment must therefore draw more heavily on analytical models, theory, and expert testimony than most popular methods.</p>

            <h2>Need for AI Probabilistic Risk Assessment</h2>

            <p>The unique characteristics of AI systems demand specialized risk assessment methodologies. Key factors driving this need include:</p>

            <ul>
                <li><b>Rapid risk development:</b> The rapid pace of development toward general-purpose AI systems, which may introduce significant hazards, necessitates specialized assessment procedures to ensure their safety.</li>
                
                <li><b>Limitations of current methods:</b> Traditional risk assessment approaches do not adequately address the complexity and scale of AI risks. Many more parties need to think about risk management for AI as a differential threat assessment for the world.</li>
                
                <li><b>Prospective assessment:</b> Methods must identify and model latent risks beyond those that can be easily elicited before they manifest, due to the scale of risks.</li>
                
                <li><b>Regulatory demand:</b> Regulators require a broader and deeper mix of methods to evaluate AI systems and establish meaningful safety thresholds.</li>
            </ul>

            <p>The application of well-established risk management, system safety engineering, and probabilistic risk assessment methodologies to general-purpose AI systems has been conspicuously absent, despite their proven effectiveness in other fields. This makes the urgency of developing a structured risk assessment method for AI urgent and crucial.</p>
                        
            <h2>Comparison of Risk Assessment Methods</h2>

            <p>Current AI risk assessment methods vary in their approach and effectiveness. In particular, they vary across the following criteria for comprehensive threat surface analysis:</p>

            <ul>
                <li>A method can operate at different levels of detail. Fine-grained methods enable detailed analysis of specific risk components, while coarse-grained methods provide higher-level system assessment.</li>
                
                <li>A method can cover more or less of the societal threat surface, e.g., by number of threat models.</li>
                
                <li>A method can provide systematic guidance over the threat surface of AI risk — or, it can lack such guidance.</li>
                
                <li>A method can be more or less informed by a specific system's characteristics — for example, specific capabilities or features.</li>
                
                <li>A method can be a better or worse proxy for safety.</li>
                
                <li>A method can be more or less robust to mitigation failure. A robust method includes the possibility of mitigation failure, estimates its likelihood, and prices it in.</li>
                
                <li>A method can be more or less "objective." An objective method requires little or no subjective input — more example, a benchmark is an objective method.</li>
                
                <li>A method can support prospective analysis of a system's risk — that is, it can identify leading indicators of risk, rather than retrospective evaluation once a system is already developed or deployed.</li>
                
                <li>A method can consider harm severity in addition to likelihood, or only consider likelihood.</li>
            </ul>

            <p>Figure 1 compares current evaluation methods across these criteria. Ratings were assigned based on expert analysis of each method's capabilities and limitations. High (H) indicates strong performance or comprehensive coverage of the criterion, Medium (M) indicates partial fulfillment, and Low (L) indicates minimal or no attention to the criterion.</p>
            <!-- <figure>
                <img src="Images/heatmap.png" alt="Comparison of Risk Assessment Methods" class="flowchart">
                <figcaption>Figure 1: Comparison of Risk Assessment Methods. <br>
                    Legend: H = High, M = Medium, L = Low. Scores indicate the degree to which each method
addresses or fulfills the given criterion
                </figcaption>
            </figure> -->
            <figure>
              <div class="assessment-matrix">
               <div class="matrix-header">
                 <!-- Category Headers -->
                 <div class="matrix-row category-headers">
                   <div class="method-col"></div>
                   <div class="criteria-cols">
                     <div class="category-section span-4">Coverage & Depth</div>
                     <div class="category-section span-3">Methodological Robustness</div>
                     <div class="category-section span-2">Assessment Structure</div>
                   </div>
                 </div>
              
                 <!-- Criteria Headers -->
                 <div class="matrix-row criteria-row">
                   <div class="method-col"></div>
                   <div class="criteria-cols">
                     <!-- Coverage & Depth -->
                     <div class="criteria">Fine-grain</div>
                     <div class="criteria">Threat Surface<br/>Coverage</div>
                     <div class="criteria">Threat Surface<br/>Guidance</div>
                     <div class="criteria">Guidance By<br/>System Property</div>
                     <!-- Methodological Robustness -->
                     <div class="criteria">Good Proxy<br/>to Safety</div>
                     <div class="criteria">Robust to<br/>Mitigation Failure</div>
                     <div class="criteria">Enforces<br/>Objectivity</div>
                     <!-- Assessment Structure -->
                     <div class="criteria">Supports<br/>Prospective Analyses</div>
                     <div class="criteria">Considers<br/>Harm Severity</div>
                   </div>
                 </div>
               </div>
              
               <div class="matrix-body">
                 <div class="matrix-row">
                   <div class="method-col">Safety Benchmarks<br/>(No Holdout)</div>
                   <div class="criteria-cols">
                     <div class="score high">High</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Safety Benchmarks<br/>(Private Holdout)</div>
                   <div class="criteria-cols">
                     <div class="score high">High</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score high">High</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Evals</div>
                   <div class="criteria-cols">
                     <div class="score high">High</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Responsible Scaling<br/>Policies</div>
                   <div class="criteria-cols">
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Safety Cases</div>
                   <div class="criteria-cols">
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score high">High</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Probabilistic Risk<br/>Assessment</div>
                   <div class="criteria-cols">
                     <div class="score medium">Medium</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                     <div class="score low">Low</div>
                     <div class="score high">High</div>
                     <div class="score high">High</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Typical Narrow AI<br/>Safety Audits</div>
                   <div class="criteria-cols">
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Deep Bespoke AI<br/>Safety Audits</div>
                   <div class="criteria-cols">
                     <div class="score high">High</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score low">Low</div>
                     <div class="score high">High</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                   </div>
                 </div>
              
                 <div class="matrix-row">
                   <div class="method-col">Scalable (AGI)<br/>Safety Audits</div>
                   <div class="criteria-cols">
                     <div class="score high">High</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score high">High</div>
                     <div class="score medium">Medium</div>
                     <div class="score medium">Medium</div>
                     <div class="score low">Low</div>
                     <div class="score medium">Medium</div>
                   </div>
                 </div>
               </div>
              </div>
              <figcaption>Figure 1: Comparison of Risk Assessment Methods.
              Ratings indicate the degree to which each method addresses or fulfills the given criterion</figcaption>
              </figure>
            <p>A comparative analysis of AI risk assessment methods demonstrates that no single approach excels across all criteria, highlighting the need for a multi-faceted approach. In particular, many current methods struggle with threat surface coverage and robustness to mitigation failure. However, probabilistic risk assessment shows the most balanced performance across dimensions. A forthcoming paper, defining the societal threat surface, will provide a more detailed explanation of risk assessment gaps and how available methods compare.</p>
            <h2>Benefits of the PRA for AI Framework</h2>

            <p>The Probabilistic Risk Assessment (PRA) AI framework offers several key benefits that address the unique challenges of AI risk assessment:</p>

            <ul>
                <li><b>Variable-resolution analysis:</b> The framework supports assessments scaling from quick high-level risk scans to comprehensive technical analysis of specific risk pathways, with clear documentation of scenarios and reasoning at each level.</li>
                
                <li><b>Comprehensive system aspect coverage:</b> The framework uses a first principles top-down taxonomy of aspect-oriented AI hazards that covers capabilities, high-risk knowledge Domains, operational affordances, and sociotechnical impact domains. It captures first and second order risks, considering effects on individuals, society, and the biosphere.</li>
                
                <li><b>Risk coverage:</b> The framework offers a top-down perspective on the hazards from general purpose AI systems. This includes a structured approach to examining both competence-based and incompetence-based hazards across the AI system's capabilities, high-risk knowledge domains and operational affordances.</li>
                
                <li><b>Consideration of direct and systemic risks:</b> The framework allows for the assessment of both immediate, direct harms and more subtle, long-term systemic risks.</li>
                
                <li><b>Explicit assumptions and likelihood documentation:</b> The framework prompts assessors to make their detailed assumptions, reasoning and estimates explicit. This transparency enhances the reliability and reproducibility of the assessment process.</li>
                
                <li><b>Integration with assessment methods:</b> The framework unifies and incorporates diverse assessment approaches within a structured evaluation framework. This allows assessment teams to incorporate existing safety cases, benchmarking or evaluation data and other risk assessment methods alongside or within the PRA methodology.</li>
            </ul>

            <h2>Framework Limitations</h2>
            <p>There are some weaknesses in the PRA for AI framework: </p>
            <ul>
                <li><strong>Subjectivity in probability estimates:</strong> The framework requires careful calibration of probability estimates across assessors, particularly for novel scenarios without historical precedent. This could lead to inconsistent assessments.</li>
                <li><strong>Rapid AI advancement challenges:</strong> The fast-paced evolution of AI capabilities may outpace the assessment process, making some evaluations quickly outdated.</li>
                <li><strong>Unknown unknowns:</strong> PRA may not adequately capture unforeseen risks or emergent behaviors in advanced AI systems.</li>
                <li><strong>Potential for anchoring bias:</strong> Predefined categories and examples might inadvertently anchor assessors' thinking, limiting consideration of unconventional scenarios.</li>
                <li><strong>Resource intensity:</strong> Thorough PRAs require significant time and expertise, which may be challenging for smaller organizations or rapid development cycles.</li>    
            </ul>

            <p>For a detailed methodology of the PRA framework, please refer to our  <a href="paper.html">paper</a>.</p>
         </div>
    </main>
    <div class="header-bar">‎</div>
    <footer>
        <div class="footer-content">
            <div class="footer-title">CENTER FOR AI RISK MANAGEMENT & ALIGNMENT</div>
            <div class="footer-copyright">COPYRIGHT © 2024 CENTER FOR AI RISK MANAGEMENT & ALIGNMENT - ALL RIGHTS RESERVED.</div>
        </div>
    </footer>
    <div id="imageModal" class="modal">
        <img class="modal-content" id="modalImage">
    </div>
    <script>
        if (window.matchMedia("(max-width: 768px)").matches) {

            var modal = document.getElementById('imageModal');
            var modalImg = document.getElementById("modalImage");
        
            var images = document.querySelectorAll('img.flowchart');
        
            images.forEach(function(img) {
                img.style.cursor = 'pointer'; 
                img.addEventListener('click', function() {
                    modal.style.display = "block";
                    modalImg.src = this.src;
                });
            });
        
        
            modal.onclick = function(event) {
                if (event.target == modal) {
                    modal.style.display = "none";
                }
            }
        }
        </script>
</body>
</html>